{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['SERPER_API_KEY']\n",
    "os.environ['LANGSMITH_API_KEY']\n",
    "os.environ['LANGSMITH_PROJECT']\n",
    "os.environ['TAVILY_API_KEY']\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD AND cHUNK dATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DirectoryLoader(r'../data',glob=\"./*.txt\",loader_cls=TextLoader)\n",
    "docs=loader.load()\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings2 = [doc.page_content for doc in new_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama3.2\",\n",
    ")\n",
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '../data/sample.txt'}\n",
      "consumer spending domestically has driven economic momentum.\n",
      "page_content='consumer spending domestically has driven economic momentum.' metadata={'source': '../data/sample.txt'}\n",
      "page_content='Indiaâ€™s last eight years of GDP (hypothetical data):' metadata={'source': '../data/sample.txt'}\n",
      "page_content='consumer demand for electronics, automobiles, and pharmaceuticals.' metadata={'source': '../data/sample.txt'}\n"
     ]
    }
   ],
   "source": [
    "query=\"Tell me about India's Industrial Growth?\"\n",
    "sample=retriever.get_relevant_documents(query)\n",
    "print(sample[0].metadata)\n",
    "print(sample[0].page_content)\n",
    "\n",
    "for i in sample:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions Pydantiucs Agent State\n",
    "\n",
    "1. This defines a TypedDict called AgentState that has a single field messages. It uses Python's typing system where:\n",
    "\n",
    "2. Sequence[BaseMessage] indicates it holds a sequence of BaseMessage objects\n",
    "3. Annotated with operator.add suggests these messages can be combined/concatenated\n",
    "4. TypedDict is a special kind of dictionary that specifies types for its keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "from pydantic import BaseModel , Field\n",
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic: str = Field(description='Selected Topic')\n",
    "    Reasoning: str = Field(description='Reasoning behind topic selection')\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "parser = PydanticOutputParser(pydantic_object=TopicSelectionParser)\n",
    "llm=ChatOllama(model=\"llama3.2\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_text(state):\n",
    "    message=state['messages']\n",
    "    question=message[-1]\n",
    "    print(question)\n",
    "    template=\"\"\"\n",
    "    Your task is to classify the given user query into one of the following categories: [India, Not Related]. \n",
    "    Only respond with the category name and nothing else.\n",
    "\n",
    "    User query: {question}\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    prompt=PromptTemplate(template=template,input_variables=[question],partial_variables={\n",
    "                                        \"format_instructions\" : parser.get_format_instructions()    }                                \n",
    "                                    )\n",
    "    \n",
    "    chain=prompt |llm |parser\n",
    "    response = chain.invoke({\"question\":question,\"format_instructions\" : parser.get_format_instructions() })\n",
    "    print(response)\n",
    "    return {\"messages\": [response.Topic]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about India's Industrial Growth\n",
      "Topic=\"India's Industrial Growth\" Reasoning='Not Related'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [\"India's Industrial Growth\"]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state={\"messages\": [\"Tell me about India's Industrial Growth\"]}\n",
    "find_relevant_text(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
